{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property-based + statistical testing\n",
    "\n",
    "Here we will introduce a powerful concept for testing your code and validating data \n",
    "using property-based testing. We will make use of the [Hypothesis](https://hypothesis.readthedocs.io/en/latest/)\n",
    "library and its integration with Pandas and Pandera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Synthesis\n",
    "\n",
    "Pandera provides a utility for generating synthetic data purely from pandera schema or schema component objects. Under the hood, the schema metadata is collected to create a data-generating strategy using [hypothesis](https://hypothesis.readthedocs.io/), which is a property-based testing library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage\n",
    "\n",
    "Let's define an example dataframe model and use its `.example()` method to generate a sample dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera as pa\n",
    "\n",
    "class DFModel(pa.DataFrameModel):\n",
    "    # note here we do not use the `Series` type hint\n",
    "    # this is possible, pandera assumes the type is `Series` by default\n",
    "    column1: int = pa.Field(lt=10)\n",
    "    column2: float = pa.Field(gt=0.25, nullable=True)\n",
    "    column3: str = pa.Field(str_contains=\"spam\")\n",
    "\n",
    "    # We can define custom checks as class methods\n",
    "    # However, this would slow down the strategies\n",
    "    # unless we create a custom strategy, which is an advanced topic\n",
    "\n",
    "    # @pa.check(\"column1\", name=\"foobar\")\n",
    "    # def is_odd(cls, column1: Series[int]) -> Series[bool]:\n",
    "    #     return column1.mod(2).eq(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFModel.example(size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few observations:\n",
    "* The schema conforms to the constraints.\n",
    "* The data may look a bit strange; this is on purpose as hypothesis is basically trying to break your code by generating edge cases 😏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "1. Try to generate a bit more examples (by simply re-running the cell) and look at what is generated.\n",
    "2. Make `column2` values to be between 0.25 and 1.0.\n",
    "3. Make `column3` values end by `\"spam\"`.\n",
    "\n",
    "*Optional:*\n",
    "\n",
    "4. Add an index type to the schema.\n",
    "5. Make index `str` type, unique, and consisting only of single small caps letters `a-z`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using strategies in property-based testing\n",
    "\n",
    "Pandera models also export `strategy` method that returns a hypothesis strategy for generating data from the schema. This can be used in property-based testing to generate data for testing.\n",
    "\n",
    "Say we would like test a function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def column2_remainder(df: pd.DataFrame) -> float:\n",
    "    return (df[\"column2\"] - 0.25).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One assumption we can make is that the result is always >= 0. We can use the `strategy` method to generate data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis import given\n",
    "\n",
    "@given(df=DFModel.strategy())\n",
    "def test_column2_remainder_is_positive(df: pd.DataFrame) -> None:\n",
    "    assert column2_remainder(df) >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we can run this test directly here (which would not be possible with plain pytest tests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_column2_remainder_is_positive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** For the functions defined below:\n",
    "1. Write a property-based test for `remove_spam` that checks there is no more spam (i.e. that `column3` values do not include \"spam\") in the output.\n",
    "2. Write a property-based test for `multiply_large` that checks the number of rows in the output.\n",
    "3. If you find a bug, try to fix it.\n",
    "\n",
    "*Optional:*\n",
    "\n",
    "4. Write more property-based tests for the two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera.typing import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "def remove_spam(df: DataFrame[DFModel]) -> DataFrame[DFModel]:\n",
    "    return df.assign(column3=df[\"column3\"].str.replace(\"spam\", \"\"))\n",
    "\n",
    "\n",
    "def multiply_large(df: DataFrame[DFModel], limit: int = 5) -> DataFrame[DFModel]:\n",
    "    # repeat the rows with column1 > limit\n",
    "    # e.g. if limit = 5, and there are 2 rows with column1 > 5\n",
    "    # then the resulting dataframe will have 4 rows with column1 > 5\n",
    "    large_rows = df[df[\"column1\"] > limit]\n",
    "    return pd.concat([df, large_rows] * 2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis strategies for scientific stack\n",
    "\n",
    "The Hypothesis package has a number of strategies already implemented, and in particular\n",
    "many useful ones for the scientific stack. See the [Hypothesis documentation](https://hypothesis.readthedocs.io/en/latest/numpy.html) for more details.\n",
    "\n",
    "As an example, we will define a strategy for generating dataframes that can be used to test `test_column2_remainder_is_positive`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis.extra.pandas import column, data_frames, range_indexes\n",
    "\n",
    "df_strategy = data_frames(\n",
    "    [\n",
    "        column(\"column1\", dtype=int),\n",
    "        column(\"column2\", dtype=float),\n",
    "        column(\"column3\", dtype=str),\n",
    "    ],\n",
    "    index=range_indexes(min_size=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strategy.example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis import given\n",
    "\n",
    "@given(df=df_strategy)\n",
    "def test_column2_remainder_is_positive_2(df: pd.DataFrame) -> None:\n",
    "    assert column2_remainder(df) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_column2_remainder_is_positive_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a hypothesis strategy to test a Pandera model.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis.extra.pandas import column, data_frames, range_indexes\n",
    "from hypothesis.strategies import floats\n",
    "import pandera.errors\n",
    "import pytest\n",
    "\n",
    "\n",
    "ivalid_df_strategy = data_frames(\n",
    "    [\n",
    "        column(\"column1\", dtype=int),\n",
    "        column(\"column2\", dtype=float, elements=floats(max_value=0.24)),\n",
    "        column(\"column3\", dtype=str),\n",
    "    ],\n",
    "    index=range_indexes(min_size=1),\n",
    ")\n",
    "\n",
    "@given(df=ivalid_df_strategy)\n",
    "def test_df_model_validation_fails(df: pd.DataFrame) -> None:\n",
    "    with pytest.raises(pandera.errors.SchemaError):\n",
    "        # ensure the validation always fails\n",
    "        DFModel.validate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_model_validation_fails()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Write a property-based test (or more tests) for the `pandas.DataFrame.drop_duplicates()` method. You probably do not need a Pandera model for this. Let's see if we find a bug in Pandas 😈!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Data Validation\n",
    "\n",
    "Pandera enables you to perform statistical hypothesis tests on your data.\n",
    "We will not cover this topic here, please read more in the [Pandera documentation](https://pandera.readthedocs.io/en/stable/hypothesis.html).\n",
    "\n",
    "Also note there are other tools that can be used for this purpose, such as [Great Expectations](https://greatexpectations.io/) or [Frictionless Data](https://frictionlessdata.io/) or [pydeequ](https://pypi.org/project/pydeequ/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robust-pandas-europython-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
