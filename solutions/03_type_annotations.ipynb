{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type annotations and dataframe models\n",
    "\n",
    "We are making use of Python type annotations (or type hints).\n",
    "\n",
    "Why type annotations are good:\n",
    "* They make code easier to read and understand (either for humans or e.g. for IDE's).\n",
    "* They make code easier to maintain and refactor.\n",
    "* Static type checkers and code analysis can catch errors before the code is run.\n",
    "* Libraries like dataclasses, attrs, Pydantic or Pandera can use type annotations to define types and validate data.\n",
    "\n",
    "Why type annotations are sometimes hard:\n",
    "* Python type systems is not perfects as it has not been designed for static typing from the beginning.\n",
    "* Libraries like Pandas use a lot of dynamic typing and are not easy to type hint and check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type annotations use cases\n",
    "\n",
    "### A simple case for functions\n",
    "\n",
    "```python\n",
    "def add_integers(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "```\n",
    "\n",
    "\n",
    "### Dataclass definitions\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "import datetime\n",
    "\n",
    "@dataclass\n",
    "class Person:\n",
    "    name: str\n",
    "    date_of_birth: datetime.date\n",
    "```\n",
    "\n",
    "### A generics example\n",
    "\n",
    "```python\n",
    "from typing import TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def first_element(items: list[T]) -> T:\n",
    "    return items[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type hints for Pandas\n",
    "\n",
    "Pandas is a bit special as it uses a lot of dynamic typing and is not easy to type hint and check.\n",
    "E.g., `DataFrame` is quite a complex type with parametrised (d)types of columns or index.\n",
    "That's why the [pandas-stubs](https://github.com/pandas-dev/pandas-stubs) project \n",
    "was only recently adopted by the Pandas team and is still incomplete and in development.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "temp_wind = pd.DataFrame(\n",
    "    {\"temperature\": [15, 16.5, 17.3], \"wind_direction\": [\"N\", \"N\", \"W\"]},\n",
    "    index=pd.date_range(\"2021-01-01\", \"2021-01-03\"),   \n",
    ").astype({\"temperature\": np.float32, \"wind_direction\": pd.StringDtype(\"pyarrow\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A straightforward type hint for a `DataFrame` would be:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def analyse_wind(wind_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    ...\n",
    "```\n",
    "\n",
    "This is definitely a good minimum. Howevern, can you guess the correct type annotation for `df` that would describe the column and index names and types?\n",
    "\n",
    "Note that we do not include `pandas-stubs` in the requirements (although we tested it)---it'd simply be t\n",
    "oo much effort and likely `# type: ignore` would be needed in many places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandera DataFrame Models\n",
    "\n",
    "Pandera introduced [DataFrame Models](https://pandera.readthedocs.io/en/stable/dataframe_models.html),\n",
    "a concept derived from Pydantic models. This concept provides a means to type annotate Pandas DataFrames,\n",
    "and, to validate data. An [integration with mypy](https://pandera.readthedocs.io/en/stable/mypy_integration.html#mypy-integration) exists. Unfortunately, at the time of writing, there was a bug in this integration for `Union` (hence also `Optional`).\n",
    "types so we do not use it. See the corresponding [Github issue](https://github.com/unionai-oss/pandera/issues/1204).\n",
    "\n",
    "\n",
    "Quoting the documentation of Pandera:\n",
    "\n",
    "> Pandera provides a class-based API that’s heavily inspired by pydantic. In contrast to the object-based API, you can define dataframe models in much the same way you’d define pydantic models.\n",
    "\n",
    "* This is also similar to how `dataclasses` or `attrs` work. \n",
    "* We will see how it differs from the object-based API later.\n",
    " \n",
    "> `DataFrameModel`s are annotated with the `pandera.typing` module using the standard typing syntax. Models can be explicitly converted to a `DataFrameSchema` or used to validate a `DataFrame` directly.\n",
    "\n",
    "> Note: Due to current limitations in the pandas library (see discussion here), pandera annotations are only used for run-time validation and has limited support for static-type checkers like mypy. See the Mypy Integration for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage\n",
    "\n",
    "This is an example from Pandera documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from pandera.typing import DataFrame, Series\n",
    "\n",
    "\n",
    "class InputSchema(pa.DataFrameModel):\n",
    "    year: Series[int] = pa.Field(gt=2000, coerce=True)\n",
    "    month: Series[int] = pa.Field(ge=1, le=12, coerce=True)\n",
    "    day: Series[int] = pa.Field(ge=0, le=365, coerce=True)\n",
    "\n",
    "class OutputSchema(InputSchema):\n",
    "    revenue: Series[float]\n",
    "\n",
    "@pa.check_types\n",
    "def transform(df: DataFrame[InputSchema]) -> DataFrame[OutputSchema]:\n",
    "    return df.assign(revenue=100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: \n",
    "1. Try to input an invalid DataFrame to `transform` function and see what happens.\n",
    "2. Try to feed a dataframe with an extra column. It should not fail.\n",
    "3. Add a `strict` option so that the validation fails if there are extra columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid column name\n",
    "invalid_df_1 = pd.DataFrame(\n",
    "    {\n",
    "        \"year\": [2021, 2021, 2021],\n",
    "        \"month\": [1, 1, 1],\n",
    "        \"date\": [1, 1, 1],\n",
    "    }\n",
    ")\n",
    "\n",
    "# invalid value\n",
    "invalid_df_2 = pd.DataFrame(\n",
    "    {\n",
    "        \"year\": [2021, 2021, 2021],\n",
    "        \"month\": [1, 1, 0],\n",
    "        \"day\": [1, 1, 1],\n",
    "    }\n",
    ")\n",
    "\n",
    "transform(invalid_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_extra_column = pd.DataFrame(\n",
    "    {\n",
    "        \"year\": [2021, 2021, 2021],\n",
    "        \"month\": [1, 1, 1],\n",
    "        \"day\": [1, 1, 1],\n",
    "        \"weekday\": [\"Monday\", \"Tuesday\", \"Wednesday\"],\n",
    "    }\n",
    ")\n",
    "transform(df_with_extra_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a `strict` option so that the validation fails if there are extra columns.\n",
    "\n",
    "class InputSchema(pa.DataFrameModel):\n",
    "    year: Series[int] = pa.Field(gt=2000, coerce=True)\n",
    "    month: Series[int] = pa.Field(ge=1, le=12, coerce=True)\n",
    "    day: Series[int] = pa.Field(ge=0, le=365, coerce=True)\n",
    "\n",
    "    class Config:\n",
    "        strict = True\n",
    "\n",
    "# we need to re-define the function so that the updated model is used\n",
    "@pa.check_types\n",
    "def transform(df: DataFrame[InputSchema]) -> DataFrame[OutputSchema]:\n",
    "    return df.assign(revenue=100.0)\n",
    "\n",
    "# this will raise an error now\n",
    "transform(df_with_extra_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrized dtypes\n",
    "\n",
    "Pandas supports a couple of parametrized dtypes, e.g. `DatetimeTZDtype`, `StringDtype` or `CategoricalDtype`.\n",
    "These type parameters can be provided via `typing.Annotated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from pandera.typing import Index, Series\n",
    "from typing import Annotated\n",
    "\n",
    "class TempWindModel(pa.DataFrameModel):\n",
    "    temperature: Series[np.float32] = pa.Field(coerce=True)\n",
    "    wind_direction: Series[Annotated[pd.StringDtype, \"pyarrow\"]] = pa.Field(coerce=True)\n",
    "    idx: Index[pd.Timestamp] = pa.Field(coerce=True, check_name=False)\n",
    "\n",
    "    class Config:\n",
    "        strict = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "1. Try to validate the `temp_wind` dataframe defined below using the `TempWindSchema` schema.\n",
    "2. Verify that `temp_wind.astype({\"wind_direction\": pd.StringDtype(\"python\")})` (i.e. the dataframe with `wind_direction` as a python string backend dtype) is still successfully validated.\n",
    "3. Modify the `Field` parameters of the `wind_direction` columns so the the validation in point 2. fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_wind = pd.DataFrame(\n",
    "    {\"temperature\": [15, 16.5, 17.3], \"wind_direction\": [\"N\", \"N\", \"W\"]},\n",
    "    index=pd.date_range(\"2021-01-01\", \"2021-01-03\"),\n",
    ").astype({\"wind_direction\": \"string[pyarrow]\", \"temperature\": \"float32\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Try to validate the `temp_wind` dataframe defined below using the `TempWindSchema` schema.\n",
    "\n",
    "TempWindModel.validate(temp_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Verify that `temp_wind.astype({\"wind_direction\": pd.StringDtype(\"python\")})`\n",
    "# (i.e. the dataframe with `wind_direction` as a python string backend dtype)\n",
    "# is still successfully validated.\n",
    "\n",
    "TempWindModel.validate(temp_wind.astype({\"wind_direction\": pd.StringDtype(\"python\")}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Modify the `Field` parameters of the `wind_direction` columns so the the validation in point 2. fails.\n",
    "\n",
    "class TempWindModel(pa.DataFrameModel):\n",
    "    temperature: Series[np.float32] = pa.Field(coerce=True)\n",
    "    # coerce=False will fail the validation\n",
    "    wind_direction: Series[Annotated[pd.StringDtype, \"pyarrow\"]] = pa.Field(coerce=False)\n",
    "    idx: Index[pd.Timestamp] = pa.Field(coerce=True, check_name=False)\n",
    "\n",
    "    class Config:\n",
    "        strict = True\n",
    "\n",
    "TempWindModel.validate(temp_wind.astype({\"wind_direction\": pd.StringDtype(\"python\")}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robust-pandas-europython-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
